# Jetson YOLOv8 TensorRT Pipeline

A Dockerized pipeline for running **YOLOv8 object detection** on NVIDIA Jetson devices using **TensorRT** for optimized inference.
Includes services for model export, live preview, and alerting (e.g., Telegram notifications).

---

## ğŸ“¦ Requirements

* NVIDIA Jetson device (Orin, Xavier, Nano, etc.)
* JetPack 6.x with CUDA and TensorRT installed
* Docker & Docker Compose with NVIDIA runtime
* `.env` file containing your configuration (see below)

---

## âš™ï¸ Environment Variables (`.env`)

Create a `.env` file in the project root:

```env
# Model configuration
YOLO_MODEL=yolov8n.pt         # Base YOLOv8 model to export
YOLO_ENGINE=yolov8n.engine    # Name of the generated TensorRT engine
CONF_THRESH=0.80               # Detection confidence threshold
IMG_SIZE=608                   # Inference resolution

# Source stream (can be RTSP, USB, or file path)
SRC=rtsp://user:pass@camera-ip:554/stream

# Tracking
TRACKER=bytetrack.yaml
VID_STRIDE=6
MAX_FPS=2

# Triggering & Drawing
DRAW_CLASSES=person,car,dog,cat
TRIGGER_CLASSES=person
MIN_FRAMES=3
MIN_PERSIST_SEC=1.0
REARM_SEC=10
RATE_WINDOW_SEC=5

# Optional zone filtering (polygon points: x,y;x,y;...)
ZONE=

# Telegram alerting (optional)
TELEGRAM_TOKEN=your_bot_token
TELEGRAM_CHAT_ID=your_chat_id
```

---

## ğŸ Python Dependencies (for non-Docker testing)

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Features

* **Optimized Inference** â€” YOLOv8 â†’ TensorRT FP16 engine for NVIDIA Jetson (Orin, Xavier, Nano, etc.).
* **Modular Services**:

  * **`exporter`** â€” Converts YOLOv8 PyTorch model to TensorRT.
  * **`jetson-yolo`** â€” Base container for running detection or CLI commands.
  * **`preview`** â€” Live stream overlay (RTSP, USB, file).
  * **`alert`** â€” Event-based object detection alerts with tracking & throttling.
* **Object Tracking** â€” Uses ByteTrack for persistent IDs.
* **Zone-based Triggers** â€” Alerts only for detections inside defined polygons.
* **Telegram Notifications** â€” Sends text + image snapshots of detections.
* **Configurable via `.env`** â€” Tune FPS, confidence thresholds, object classes, etc.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ alert.py           # Alerting & tracking service
â”‚   â”œâ”€â”€ export_engine.py   # YOLOv8 â†’ TensorRT export script
â”œâ”€â”€ work/                  # Mounted workspace for models, logs, alerts
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ³ Running the Pipeline

### 1ï¸âƒ£ Build the Docker image

```bash
docker compose build
```

### 2ï¸âƒ£ Export TensorRT Engine

```bash
docker compose run --rm exporter
```

### 3ï¸âƒ£ Start Detection + Alert Services

```bash
docker compose up alert
```

### 4ï¸âƒ£ Live Preview (Optional)

```bash
docker compose up preview
```

---

## ğŸ”” Alert Logic

* Tracks objects using **ByteTrack**.
* Only triggers if:

  * Object class is in `TRIGGER_CLASSES`.
  * Confidence â‰¥ `CONF_THRESH`.
  * Persists for at least `MIN_PERSIST_SEC` and `MIN_FRAMES` frames.
  * (Optional) Center point inside defined `ZONE`.
* Groups multiple detections into a single Telegram alert per `RATE_WINDOW_SEC`.

---

## ğŸ› ï¸ Development & Testing

Run commands inside the container:

```bash
docker compose run --rm jetson-yolo bash
```

Example YOLOv8 prediction test:

```bash
yolo predict source="$SRC" model="$YOLO_ENGINE" device=0
```

---

## ğŸ“œ License

MIT â€” feel free to modify and adapt.
